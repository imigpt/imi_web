<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>IMI Voice Assistant</title>
  <style>
* {
  box-sizing: border-box;
}

body {
  margin: 0;
  padding: 0;
  background-color: #000;
  font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
  color: white;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  height: 100vh;
  text-align: center;
  overflow: hidden;
}

.mic-button {
  width: 80px;
  height: 80px;
  border-radius: 50%;
  background: radial-gradient(circle at center, #ff00ff, #6e00ff);
  display: flex;
  align-items: center;
  justify-content: center;
  box-shadow: 0 0 20px #ff00ff88;
  margin-bottom: 20px;
  cursor: pointer;
  transition: transform 0.2s ease;
}

.mic-button:hover {
  transform: scale(1.1);
}

.mic-button i {
  font-size: 28px;
  color: white;
}

.title {
  font-size: 5vw;
  font-weight: 300;
  margin-bottom: 5px;
}

.brand {
  font-size: 7vw;
  font-weight: bold;
  color: #ffffff;
  margin-bottom: 5px;
}

.subtitle {
  font-size: 3.5vw;
  color: #bbb;
  margin-bottom: 30px;
  padding: 0 20px;
}

#log {
  max-height: 120px;
  overflow-y: auto;
  font-size: 3vw;
  padding: 10px;
  text-align: left;
  width: 90%;
  margin: auto;
  display: none;
}

audio {
  display: none;
}

  </style>
  <script src="https://kit.fontawesome.com/a076d05399.js" crossorigin="anonymous"></script>
</head>
<body>

  <div class="mic-button" id="startBtn">
    <i class="fas fa-microphone"></i>
  </div>

  <div class="title">Effortless control with</div>
  <div class="brand">IMI</div>
  <div class="subtitle">We believe in the power of voice to transform the way you work</div>

  <div id="log"></div>
  <audio id="audioPlayer" controls></audio>

  <script>
    let socket;
    let mediaRecorder;
    let audioChunks = [];
    let vadInterval;
    let analyser;
    let audioContext;
    let micStream;

    document.getElementById('startBtn').onclick = async function () {
      socket = new WebSocket("wss://tdotl5s0nofznv-8000.proxy.runpod.net/ws/assistant");

      socket.onopen = async function () {
        log("‚úÖ Connected to Assistant!");
        await startMic();
      };

      socket.onmessage = function (event) {
        log(event.data);
        const response = JSON.parse(event.data);
        if (response.audio_url) {
          playAudio(response.audio_url);
        }
      };

      socket.onclose = function () {
        log("‚ùå Connection closed.");
        stopMic();
      };

      socket.onerror = function (error) {
        log("‚ùå Error: " + error.message);
      };
    };

    function log(message) {
      const logDiv = document.getElementById('log');
      const p = document.createElement('p');
      p.textContent = message;
      logDiv.style.display = 'block';
      logDiv.appendChild(p);
    }

    async function startMic() {
      micStream = await navigator.mediaDevices.getUserMedia({ audio: true });

      audioContext = new (window.AudioContext || window.webkitAudioContext)();
      analyser = audioContext.createAnalyser();
      const source = audioContext.createMediaStreamSource(micStream);
      source.connect(analyser);

      mediaRecorder = new MediaRecorder(micStream);
      audioChunks = [];

      mediaRecorder.ondataavailable = event => {
        if (event.data.size > 0) {
          audioChunks.push(event.data);
        }
      };

      mediaRecorder.onstop = async () => {
        const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
        log("üíæ Audio recorded. Sending to backend...");

        if (socket && socket.readyState === WebSocket.OPEN) {
          const reader = new FileReader();
          reader.onload = function () {
            const arrayBuffer = reader.result;
            socket.send(arrayBuffer);
          };
          reader.readAsArrayBuffer(audioBlob);
        }
      };

      mediaRecorder.start();
      log("üé§ Recording started...");
      startVAD();
    }

    function stopMic() {
      if (vadInterval) clearInterval(vadInterval);
      if (mediaRecorder && mediaRecorder.state !== "inactive") mediaRecorder.stop();
      if (micStream) micStream.getTracks().forEach(track => track.stop());
      if (audioContext) audioContext.close();
    }

    function startVAD() {
      const silenceThreshold = 0.01;
      const silenceDuration = 1500;

      let silenceStart = null;

      vadInterval = setInterval(() => {
        const dataArray = new Uint8Array(analyser.fftSize);
        analyser.getByteTimeDomainData(dataArray);

        let sumSquares = 0.0;
        for (const amplitude of dataArray) {
          const normalized = (amplitude - 128) / 128.0;
          sumSquares += normalized * normalized;
        }
        const volume = Math.sqrt(sumSquares / dataArray.length);

        if (volume < silenceThreshold) {
          if (!silenceStart) {
            silenceStart = Date.now();
          } else if (Date.now() - silenceStart > silenceDuration) {
            log("ü§´ Silence detected. Stopping recording...");
            stopMic();
          }
        } else {
          silenceStart = null;
        }
      }, 200);
    }

    function playAudio(audioData) {
      const audioPlayer = document.getElementById('audioPlayer');
      const backendBaseUrl = "https://tdotl5s0nofznv-8000.proxy.runpod.net";
      const fullAudioUrl = backendBaseUrl + audioData;

      audioPlayer.src = fullAudioUrl;
      audioPlayer.play()
        .then(() => log("üé∂ Playing audio from backend..."))
        .catch(error => log("‚ùå Error playing audio: " + error.message));

      audioPlayer.onended = function () {
        startMic();
      };
    }
  </script>
</body>
</html>
